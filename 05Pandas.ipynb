{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas!\n",
    "\n",
    "This week we'll be looking at the `pandas` module which deals with data in tables. The main feature of table data is that every column contains a particular type of data. For example, one column may contain whole numbers, another floating-point numbers, another strings and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing pandas\n",
    "\n",
    "As previously with `matplotlib`, the convention is to abbreviate `pandas`, like this:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "Try it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "In `pandas`, a table of data is called a DataFrame. There are many ways to create a DataFrame.\n",
    "\n",
    "Here we'll create one from a dictionary. In our dictionary, the key is the column name and the value is the data for that column:\n",
    "\n",
    "```python\n",
    "data_dict = {\n",
    "    \"numbers\": [56, 78, -12],\n",
    "    \"veg\": [\"spinach\", \"carrots\", \"cabbages\"]\n",
    "}\n",
    "df = pd.DataFrame(data_dict)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing values (again)\n",
    "\n",
    "You may remember that last week we looked at the difference between using `print()` with a variable, and using a variable name on its own, to see its value.\n",
    "\n",
    "Compare\n",
    "\n",
    "```python\n",
    "print(df)\n",
    "```\n",
    "\n",
    "and just\n",
    "\n",
    "```python\n",
    "df\n",
    "```\n",
    "\n",
    "Run each of these in a cell on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second one is a nicely formatted table, definitely preferable! The first is a plain text representation, designed to work in any format. The second only applies to interactive environments like Jupyter -- it would be ignored in a Python program. Also note that this trick only works for the last line in a cell.\n",
    "\n",
    "The general rule: **In an interactive environment, you can put a variable (or some code that returns a value) on the last line, and the environment will show it in the best way it can**.\n",
    "\n",
    "So for example, you can use:\n",
    "\n",
    "```python\n",
    "1000/26\n",
    "```\n",
    "\n",
    "instead of:\n",
    "\n",
    "```python\n",
    "print(1000/26)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data by column\n",
    "\n",
    "It seems somewhat unoriginal, but this structure is known as a `DataFrame` in `pandas`.\n",
    "\n",
    "You can select a whole column by using its name in square brackets:\n",
    "\n",
    "```python\n",
    "df[\"numbers\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New columns\n",
    "\n",
    "You can create a new column quite easily:\n",
    "\n",
    "```python\n",
    "df[\"morenumbers\"] = [0.1, 0.5, 0.8]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit of maths\n",
    "\n",
    "You can use arithmetic on these data in a similar way to a NumPy array, e.g.\n",
    "\n",
    "```python\n",
    "df[\"numbers\"] + 1000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect you can also work with whole columns together, as long as they are the same size:\n",
    "\n",
    "```python\n",
    "df[\"numbers\"] + df[\"morenumbers\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, you can store the result of such an operation in a new column of its own:\n",
    "\n",
    "```python\n",
    "df[\"tinynumbers\"] = df[\"numbers\"] / 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "`pandas` is good at loading data in all sorts of formats. Let's load a dataset into a table, so we have more example data to work with.\n",
    "\n",
    "As an example, we'll use some data on exoplanets (planets orbiting starts other than the Sun).\n",
    "\n",
    "Our exercise will be to find a planet that might be habitable for humans!\n",
    "\n",
    "Download the file `planets.csv` on the course web page, and upload it to the server.\n",
    "\n",
    "This file was generated from the NASA Exoplanet Archive. By way of attribution for these data:\n",
    "\n",
    "> This tutorial makes use of the NASA Exoplanet Archive, which is operated by the California Institute of Technology, under contract with the National Aeronautics and Space Administration under the Exoplanet Exploration Program.\n",
    "\n",
    "> http://exoplanetarchive.ipac.caltech.edu/\n",
    "\n",
    "CSV is the most common, and most widely used format for table data. If you need to, `pandas` will also read Excel, HDF, JSON and a few others.\n",
    "\n",
    "In this case we have the data in CSV. Try this:\n",
    "\n",
    "```python\n",
    "data = pd.read_csv(\"planets.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It failed!\n",
    "\n",
    "Real data are messy! Never mind, let's take a look and see what's wrong.\n",
    "\n",
    "Fortunately CSV data are just text, so we can easily look at the file. Click on `planets.csv` in your Jupyter files and it will show you the raw text of the file.\n",
    "\n",
    "You'll see from this that the data have a preamble with definitions of the columns. We could probably go back to NASA and get the data without the preamble, or we could delete it manually -- but a better option would be to get `pandas` to just ignore those lines. That way we keep the metadata with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Loading data into pandas\n",
    "\n",
    "Have a look at the documentation for `read_csv()`. Search and read the entry for the parameter `comment=`\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html#pandas.read_csv\n",
    "\n",
    "Use `pd.read_csv()` with this parameter, in order to ignore the preamble in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtypes\n",
    "\n",
    "In `pandas` (and `numpy`, as it happens) `dtype` means \"data type\".\n",
    "\n",
    "These data types are related to the types you're used to in Python. You can take a look at the type of a single column with, for example:\n",
    "\n",
    "```python\n",
    "data[\"pl_pnum\"].dtype\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```python\n",
    "data[\"pl_orbper\"].dtype\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case you'll see the data types are `'int64'` and `'float64'`.\n",
    "\n",
    "The first of these indicates an **integer**, i.e. whole number.\n",
    "\n",
    "The second indicates a **floating-point number**. This is a number where the digits of the number and the order of magnitude are stored separately, as in scientific notation. For example in the number\n",
    "\n",
    "$2.345 \\times 10 ^{11}$\n",
    "\n",
    "the digits of the number are 2.345 and the order of magnitude (i.e. power of 10) is 11. It isn't necessary to remember this to use floating point numbers -- just remember you'll use them where you're dealing with very large numbers or numbers with a fraction.\n",
    "\n",
    "In both cases the `64` indicates that the number is stored in 64 bits of computer memory. A bit is a binary value (0 or 1). Again, it's not necessary to understand this to use data types -- it only becomes relevant if you need to worry about very precise values, or very large amounts of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas` any non-numeric data is stored as type `object`. This means that anything you can store in Python, you can put into a `pandas` DataFrame. Typically this is used to store strings. For example:\n",
    "\n",
    "```python\n",
    "data[\"pl_hostname\"].dtype\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type given is 'O' for object.\n",
    "\n",
    "You can get all the dtypes for a DataFrame like this:\n",
    "\n",
    "```python\n",
    "data.dtypes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of a DataFrame\n",
    "\n",
    "Just like a NumPy array, you can get the size of a `DataFrame` using `.shape`:\n",
    "\n",
    "```python\n",
    "data.shape\n",
    "```\n",
    "\n",
    "You'll see that (again as in NumPy) this gives number of rows, followed by number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More information about the DataFrame\n",
    "\n",
    "You can get a summary with:\n",
    "\n",
    "```python\n",
    "data.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and labels\n",
    "\n",
    "In `pandas` every row and every column has a label. The labels are the parts shown in bold when you view the table -- see the first row and the leftmost column.\n",
    "\n",
    "Use `.loc` to index by labels. \n",
    "\n",
    "By default data loaded from CSV is labeled with:\n",
    "\n",
    "* for columns, the headers that were given in the file\n",
    "* for rows, integers starting at zero\n",
    "\n",
    "For example, you could get the 7th (index 6) element of the column \"pl_hostname\" like this:\n",
    "\n",
    "```python\n",
    "data.loc[2:6,\"pl_hostname\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.iloc` is used to index by numerical indexes. So regardless of labels, the first column (or first row) is always 0, the second is 1, and so on. Since \"pl_hostname\" is the second column, we can get the same information as the last example with:\n",
    "\n",
    "```python\n",
    "data.iloc[6,1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data\n",
    "\n",
    "Let's look for some habitable planets! First we're going to check that the estimated surface temperature is within some reasonable bounds. Let's first check it's not too hot. All the temperatures in the table are in Kelvin, so let's say that 323K (50&deg;C) is a reasonable upper bound.\n",
    "\n",
    "To filter on a particular data value, you can use something like this:\n",
    "\n",
    "```python\n",
    "data.loc[data[\"pl_eqt\"] < 323]\n",
    "```\n",
    "\n",
    "Why does this work? Try just the condition on its own:\n",
    "\n",
    "```python\n",
    "data[\"pl_eqt\"] < 323\n",
    "```\n",
    "\n",
    "This generates a column of `True` and `False` values -- plugging this in to the dataset returns only those rows where the column has `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidying up\n",
    "\n",
    "There's a lot in that `DataFrame`. To tidy it up, we can just show those columns we want.\n",
    "\n",
    "From the data file:\n",
    "\n",
    "```python\n",
    "# COLUMN pl_hostname:    Host Name\n",
    "# COLUMN pl_pnum:        Number of Planets in System\n",
    "# COLUMN pl_orbper:      Orbital Period [days]\n",
    "# COLUMN st_dist:        Distance [pc]\n",
    "# COLUMN pl_eqt:         Equilibrium Temperature [K]\n",
    "# COLUMN pl_masse:       Planet Mass [Earth mass]\n",
    "# COLUMN st_spstr:       Spectral Type\n",
    "```\n",
    "\n",
    "To ask for these, we can give a list of columns when indexing, instead of a single column:\n",
    "\n",
    "```python\n",
    "columns = [\n",
    "    \"pl_hostname\",\"pl_pnum\",\"pl_orbper\",\n",
    "    \"st_dist\",\"pl_eqt\",\"pl_masse\",\"st_spstr\"\n",
    "]\n",
    "data.loc[data[\"pl_eqt\"] < 323, columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Goldilocks\n",
    "\n",
    "Of course we want to find a planet that's not too hot or too cold.\n",
    "\n",
    "Find all the planets where the surface temperature is greater than 223 Kelvin (-50&deg;C). There are 381 of them! If you don't want to scroll down to the bottom of the table to see how many there are, remember that you can use `.shape` to check the size of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining conditions\n",
    "\n",
    "How do we combine these? Unfortunately we can't just use the word `and`, as we have before in Python.\n",
    "\n",
    "Instead `pandas` uses `&` for \"and\", `|` for \"or\", and `~` for \"not\". So here we'll use `&`, as we want both conditions to be true.\n",
    "\n",
    "```python\n",
    "data.loc[(data[\"pl_eqt\"] < 323) & (data[\"pl_eqt\"] > 223)]\n",
    "```\n",
    "\n",
    "It's important to put brackets around the conditions you're combining.\n",
    "\n",
    "Alternatively, you can evaluate your conditions first, and name them:\n",
    "\n",
    "```python\n",
    "cool_enough = data[\"pl_eqt\"] < 323\n",
    "hot_enough = data[\"pl_eqt\"] > 223\n",
    "data.loc[cool_enough & hot_enough]\n",
    "```\n",
    "\n",
    "This is clearer, and giving your conditions a name makes it clear to others (and your future self!) what the meaning of the code is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Another condition\n",
    "\n",
    "Let's say we want our planet to be orbiting a star within 100 light years of our sun. There's a column for this, the distance from our star to the remote star:\n",
    "\n",
    "```python\n",
    "# COLUMN st_dist:        Distance [pc]\n",
    "```\n",
    "\n",
    "This is in parsecs, but we want it to be in light years. One parsec is about 3.26 light years.\n",
    "\n",
    "First, create a new column called `st_dist_ly`. Set this to the distance to the remote star in light years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use a condition on that column to find only those stars within 100 light years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, combine this with the other conditions to find a planet that is not too hot, not too cold, and not too far away.\n",
    "\n",
    "You should see two planets, HD 85512-b and Proxima Cen-b.\n",
    "\n",
    "One of them is at Proxima Centauri, which is the nearest other star to the Sun!\n",
    "\n",
    "<p style=\"text-align: center\">**Proxima Centauri (NASA)**</p>\n",
    "![Proxima Centauri](http://softdev.ppls.ed.ac.uk/static/images/nasa_proxima.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
